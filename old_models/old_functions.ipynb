{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                    #arrays and matrix math\n",
    "import pandas as pd                                   #work with DataFrames\n",
    "import matplotlib.pyplot as plt                       #plotting and visualization\n",
    "import matplotlib.dates as mdates                     #datetime formate in plots\n",
    "\n",
    "import keras.backend as K                             #keras backend\n",
    "import tensorflow as tf                               #tensor operations\n",
    "import h5py                                           #import h5 files\n",
    "import os                                             #OS operations\n",
    "import time                                           #timing and clock time\n",
    "import scipy.signal as signal                         #signal processing\n",
    "from scipy.io import loadmat                          #load MatLab m-files\n",
    "from scipy.stats.qmc import LatinHypercube\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, Normalizer\n",
    "from skimage.metrics import mean_squared_error as image_mse         #Mean Squared Error\n",
    "from skimage.metrics import structural_similarity as image_ssim     #Structural Similarity Index\n",
    "from skimage.metrics import peak_signal_noise_ratio as image_psnr   #Peak Signal-Noise Ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open H5 file as Pandas DataFrame\n",
    "def open_fiber_H5_2_arr(folder_n=1, file_n=0, xstart=4950, xend=5150):\n",
    "    if folder_n==1:\n",
    "        fold = 'E:/Lytt Fiber Optics/Sintef3mH5'\n",
    "    elif folder_n==2:\n",
    "        fold = 'E:/Lytt Fiber Optics/Sintef10mH5'\n",
    "    elif folder_n==45:\n",
    "        fold = 'E:/Lytt Fiber Optics/45'\n",
    "    elif folder_n==48:\n",
    "        fold = 'E:/Lytt Fiber Optics/48'\n",
    "    elif folder_n==109:\n",
    "        fold = 'E:/Lytt Fiber Optics/109'\n",
    "    elif folder_n==128:\n",
    "        fold = 'E:/Lytt Fiber Optics/128'\n",
    "    file = os.listdir(fold)\n",
    "    file_path = os.path.join(fold, file[file_n])\n",
    "    f = h5py.File(file_path, 'r')\n",
    "    df = pd.DataFrame((f['Acquisition']['Raw[0]']['RawData'])).iloc[:, xstart:xend].T\n",
    "    f.close\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder54, files54 = 'E:/Lytt Fiber Optics/Sintef10mH5', os.listdir(folder54)               # done\n",
    "# folder64, files64 = 'E:/Lytt Fiber Optics/Sintef3mH5', os.listdir(folder64)                ########## re-do this one! (accidentally deleted)\n",
    "# folder45, files45 = 'E:/Lytt Fiber Optics/45', os.listdir(folder45)                        # done\n",
    "# folder48, files48 = 'E:/Lytt Fiber Optics/48', os.listdir(folder48)                        # done\n",
    "# folder109, files109 = 'E:/Lytt Fiber Optics/109', os.listdir(folder109)                    # done\n",
    "# folder128, files128 = 'E:/Lytt Fiber Optics/128', os.listdir(folder128)                    # done\n",
    "\n",
    "# change folder_i, files_i to desired experiment\n",
    "folder128 = 'E:/Lytt Fiber Optics/128'\n",
    "print('Experiment 128 (file128) # of files: {}'.format(len(os.listdir(folder128))))\n",
    "\n",
    "data_exp128 = pd.DataFrame(())\n",
    "for i in range(len(os.listdir(folder128))):\n",
    "    new_data1 = open_fiber_H5_2_arr(folder_n=128, file_n=i, xstart=4950, xend=5150)\n",
    "    data_exp128 = pd.concat([data_exp128, new_data1], ignore_index=True, axis=1)\n",
    "    data_exp128.to_pickle('E:/Lytt Fiber Optics/data_exp128.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('E:/Lytt Fiber Optics/DTS 45/20190620_142044328000_Sintef_2019_DTS.csv').iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'E:/Lytt Fiber Optics/DTS 109'\n",
    "files = os.listdir(folder)\n",
    "dts_exp109 = pd.DataFrame()\n",
    "for i in range(len(files)):\n",
    "    df = pd.read_csv(os.path.join(folder,files[i])).iloc[:,1]\n",
    "    dts_exp109 = pd.concat([dts_exp109, df], ignore_index=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_save_dts_data(folder, save_name, size=200):\n",
    "#     print('This is Experiment {}. Saved.'.format(folder[-2:]))\n",
    "#     ### folder1 == 'E:/Research/Lytt Fiber Optics/DTS Experiment 54' ###\n",
    "#     ### folder2 == 'E:/Research/Lytt Fiber Optics/DTS Experiment 64' ###\n",
    "#     # save depth datums\n",
    "#     dts_depths = pd.read_csv(os.path.join(folder, os.listdir(folder)[0]), usecols=[1]).squeeze()[-size:]\n",
    "#     dts_depths.to_pickle('dts_depthstamps.pkl')\n",
    "#     # save timestamps\n",
    "#     dts_timestamps = pd.Series(dtype='object')\n",
    "#     for i in range(len(os.listdir(folder))):\n",
    "#         dts_timestamps.loc[i] = pd.to_datetime(os.listdir(folder)[i][9:19], format=\"%H%M%S%f\").time()\n",
    "#     if folder[-2:]=='54':\n",
    "#         dts_timestamps.to_pickle('dts_exp54_timestamps.pkl')    \n",
    "#     elif folder[-2:]=='64':\n",
    "#         dts_timestamps.to_pickle('dts_exp64_timestamps.pkl')\n",
    "#     # save temperature data\n",
    "#     all_files  = os.listdir(folder)\n",
    "#     dts_df = pd.DataFrame(())\n",
    "#     for i in range(len(all_files)):\n",
    "#         my_file = os.listdir(folder)[i]\n",
    "#         file_path = os.path.join(folder, my_file)\n",
    "#         new_dts   = pd.read_csv(file_path, usecols=[2])\n",
    "#         dts_df = pd.concat([dts_df, new_dts], ignore_index=True, axis=1)\n",
    "#     dts_postprocess = dts_df.iloc[-size:]\n",
    "#     dts_postprocess.to_pickle(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 54 ONLY \n",
    "\n",
    "### DAS data ###\n",
    "das_exp54 = pd.read_pickle('data_exp54.pkl')\n",
    "time_complete_das_exp54 = np.array([loadmat('time_complete_54.mat')['time']], dtype='datetime64[us]').reshape(-1)\n",
    "trange_54, xrange_54 = mdates.date2num(time_complete_das_exp54), np.arange(4950, 5150)\n",
    "print('Experiment 54 DAS shape: {}'.format(das_exp54.shape))\n",
    "print('Times for Experiment 54 shape: {}'.format(time_complete_das_exp54.shape))\n",
    "print('Timerange 54: {} | X-range 54: {}'.format(trange_54.shape, xrange_54.shape))\n",
    "print('\\n')\n",
    "### DTS data ###\n",
    "dts_exp54 = pd.read_pickle('dts_exp54.pkl')\n",
    "dts_timestamp, dts_depthstamp  = pd.read_pickle('dts_exp54_timestamps.pkl'), pd.read_pickle('dts_depthstamps.pkl')\n",
    "print('Experiment 54 DTS shape: {}'.format(dts_exp54.shape))\n",
    "print('Experiment 54: times={} | depths={}'.format(dts_timestamp.shape, dts_depthstamp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(1, 1, figsize=(20,10))\n",
    "# im1 = ax1.imshow(das_exp54, aspect='auto', cmap='seismic', vmin=-50, vmax=50, extent=[trange_54[0], trange_54[-1], xrange_54[-1], xrange_54[0]])\n",
    "# ax1.xaxis_date(); ax1.xaxis.set_major_formatter( mdates.DateFormatter('%H:%M:%S'))\n",
    "# ax1.set_xlabel('Time [s] on 06/20/2019'); ax1.set_ylabel('Distance [m]'); ax1.set_title('DAS Experiment 54')\n",
    "# cbar = plt.colorbar(im1, ax=ax1, pad=0.01)\n",
    "# cbar.set_label('DAS Amplitude', rotation=270)\n",
    "# fig.autofmt_xdate()\n",
    "# plt.show();\n",
    "\n",
    "# fig, ax2 = plt.subplots(1, 1, figsize=(20,10))\n",
    "# im2 = ax2.imshow(dts_exp54, aspect='auto', cmap='seismic', vmin=-10, vmax=200, extent=[trange_54[0], trange_54[-1], xrange_54[-1], xrange_54[0]])\n",
    "# ax2.xaxis_date(); ax2.xaxis.set_major_formatter( mdates.DateFormatter('%H:%M:%S'))\n",
    "# ax2.set_title('DTS Experiment 54'); ax2.set_xlabel('Time [s] on 06/20/2019'); ax2.set_ylabel('Distance [m]')\n",
    "# cbar = plt.colorbar(im2, ax=ax2, pad=0.01)\n",
    "# cbar.set_label('DTS Temperature', rotation=270)\n",
    "# fig.autofmt_xdate()\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'E:/Lytt Fiber Optics/dts 128'\n",
    "files = os.listdir(folder)\n",
    "dts = pd.DataFrame()\n",
    "for i in range(len(files)):\n",
    "    df = pd.read_csv(os.path.join(folder,files[i])).iloc[:,1]\n",
    "    dts = pd.concat([dts, df], ignore_index=True, axis=1)\n",
    "dts_final = dts[-200:]\n",
    "dts_final.to_pickle('E:/Lytt Fiber Optics/dts_exp128.pkl')\n",
    "print(dts_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# das_dec = signal.decimate(signal.decimate(das,10),10)\n",
    "\n",
    "# flowrates = np.zeros((200,4))\n",
    "# flowrates[115] = exp_flow[0]\n",
    "# flowrates[126] = exp_flow[1]\n",
    "# flowrates[138] = exp_flow[2]\n",
    "# flowrates[142] = exp_flow[3]\n",
    "# flowrates[152] = exp_flow[4]\n",
    "\n",
    "# #X_das = np.expand_dims(my_normalize(das_dec.T, mode='minmax'), -1)\n",
    "# #X_dts = np.expand_dims(my_normalize(dts_exp54.T, mode='minmax'), -1)\n",
    "# X_das = np.expand_dims(Normalizer('max').fit_transform(das_dec.T), -1)\n",
    "# X_dts = np.expand_dims(MinMaxScaler().fit_transform(dts.T), -1)\n",
    "# y_flow = MinMaxScaler().fit_transform(flowrates)\n",
    "# print('DAS norm: ', X_das.shape)\n",
    "# print('DTS norm: ', X_dts.shape)\n",
    "# print('Flow norm:', y_flow.shape)\n",
    "\n",
    "# X_das_train = X_das[:int(X_das.shape[0]*0.8)]\n",
    "# X_das_test  = X_das[int(X_das.shape[0]*0.8):]\n",
    "\n",
    "# X_dts_train = X_dts[:int(X_dts.shape[0]*0.9)]\n",
    "# X_dts_test  = X_dts[int(X_dts.shape[0]*0.9):]\n",
    "\n",
    "# print('DAS: Train={} | Test={}'.format(X_das_train.shape, X_das_test.shape))\n",
    "# print('DTS: Train={}    | Test={}'.format(X_dts_train.shape, X_dts_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# das_train_pred = das_m2m.predict(X_das_train).squeeze().astype('float64')\n",
    "# das_test_pred = das_m2m.predict(X_das_test).squeeze().astype('float64')\n",
    "# print('Predictions: train={} | test={}'.format(das_train_pred.shape, das_test_pred.shape))\n",
    "\n",
    "# das_train_z = das_m2z.predict(X_das_train).squeeze().astype('float64')\n",
    "# das_test_z = das_m2z.predict(X_das_test).squeeze().astype('float64')\n",
    "# print('Latent Space: train={} | test={}'.format(das_train_z.shape, das_test_z.shape))\n",
    "\n",
    "# plt.figure(figsize=(10,4))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(das_train_z.reshape((das_train_z.shape[0], das_train_z.shape[1]*das_train_z.shape[-1])).T, aspect='auto', cmap='binary', vmin=0, vmax=1); \n",
    "# plt.colorbar(); plt.show()\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(das_test_z.reshape((das_test_z.shape[0], das_test_z.shape[1]*das_test_z.shape[-1])).T, aspect='auto', cmap='binary', vmin=0, vmax=1)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(30,8), facecolor='white')\n",
    "# plt.subplot(231)\n",
    "# plt.imshow(X_das_train.squeeze().T, cmap='seismic', aspect='auto', vmin=-0.1, vmax=0.1)\n",
    "# plt.colorbar(); plt.title('DAS Original - Train')\n",
    "# plt.subplot(232)\n",
    "# plt.imshow(das_train_pred.T, cmap='seismic', aspect='auto', vmin=-0.1, vmax=0.1)\n",
    "# plt.colorbar(); plt.title('DAS Reconstruction - Train')\n",
    "# plt.subplot(233)\n",
    "# plt.imshow((X_das_train.squeeze().T - das_train_pred.T)/X_das_train.squeeze().T, cmap='seismic', aspect='auto', vmin=-1, vmax=1)\n",
    "# plt.colorbar(); plt.title('Normalized Relative Error - Train')\n",
    "# plt.subplot(234)\n",
    "# plt.imshow(X_das_test.squeeze().T, cmap='seismic', aspect='auto', vmin=-0.1, vmax=0.1)\n",
    "# plt.colorbar(); plt.title('DAS Original - Test')\n",
    "# plt.subplot(235)\n",
    "# plt.imshow(das_test_pred.T, cmap='seismic', aspect='auto', vmin=-0.1, vmax=0.1)\n",
    "# plt.colorbar(); plt.title('DAS Reconstruction - Test')\n",
    "# plt.subplot(236)\n",
    "# plt.imshow((X_das_test.squeeze().T - das_test_pred.T)/X_das_test.squeeze().T, cmap='seismic', aspect='auto', vmin=-1, vmax=1)\n",
    "# plt.colorbar(); plt.title('Normalized Relative Error - Test')\n",
    "# plt.show();\n",
    "\n",
    "# das_pred = np.vstack((das_train_pred, das_test_pred))\n",
    "# plt.figure(figsize=(15,4))\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(X_das.squeeze().T, cmap='seismic', aspect='auto', vmin=-0.1, vmax=0.1)\n",
    "# plt.colorbar(); plt.title('DAS Original')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(das_pred.T, cmap='seismic', aspect='auto', vmin=-0.1, vmax=0.1)\n",
    "# plt.colorbar(); plt.title('DAS Reconstruction')\n",
    "# plt.subplot(133)\n",
    "# plt.imshow((X_das.squeeze().T - das_pred.T)/X_das.squeeze().T, cmap='seismic', aspect='auto', vmin=-1, vmax=1)\n",
    "# plt.colorbar(); plt.title('Normalized Relative Error')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dts_train_pred = dts_m2m.predict(X_dts_train).squeeze().astype('float64')\n",
    "# dts_test_pred = dts_m2m.predict(X_dts_test).squeeze().astype('float64')\n",
    "# print('Predictions: train={} | test={}'.format(dts_train_pred.shape, dts_test_pred.shape))\n",
    "# dts_train_z = dts_m2z.predict(X_dts_train).squeeze().astype('float64')\n",
    "# dts_test_z = dts_m2z.predict(X_dts_test).squeeze().astype('float64')\n",
    "# print('Latent Space: train={} | test={}'.format(dts_train_z.shape, dts_test_z.shape))\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(dts_test_z.reshape((dts_test_z.shape[0], dts_test_z.shape[1]*dts_test_z.shape[-1])).T, aspect='auto', cmap='binary', vmin=0, vmax=1)\n",
    "\n",
    "# print('Testing:')\n",
    "# print('SSIM={:.3f}'.format(structural_similarity(X_dts_test.squeeze().T, dts_test_pred.T)))\n",
    "# print('MSE={:.3e}'.format(mean_squared_error(X_dts_test.squeeze().T, dts_test_pred.T)))\n",
    "\n",
    "# plt.figure(figsize=(30,8), facecolor='white')\n",
    "# plt.subplot(231)\n",
    "# plt.imshow(X_dts_train.squeeze().T, cmap='seismic', aspect='auto', vmin=0, vmax=1)\n",
    "# plt.colorbar(); plt.title('DTS Original - Train')\n",
    "# plt.subplot(232)\n",
    "# plt.imshow(dts_train_pred.T, cmap='seismic', aspect='auto', vmin=0, vmax=1)\n",
    "# plt.colorbar(); plt.title('DTS Reconstruction - Train')\n",
    "# plt.subplot(233)\n",
    "# plt.imshow((X_dts_train.squeeze().T - dts_train_pred.T)/X_dts_train.squeeze().T, cmap='seismic', aspect='auto')\n",
    "# plt.colorbar(); plt.title('Normalized Relative Error - Train')\n",
    "# plt.subplot(234)\n",
    "# plt.imshow(X_dts_test.squeeze().T, cmap='seismic', aspect='auto', vmin=0, vmax=1)\n",
    "# plt.colorbar(); plt.title('DTS Original - Test')\n",
    "# plt.subplot(235)\n",
    "# plt.imshow(dts_test_pred.T, cmap='seismic', aspect='auto', vmin=0, vmax=1)\n",
    "# plt.colorbar(); plt.title('DTS Reconstruction - Test')\n",
    "# plt.subplot(236)\n",
    "# plt.imshow((X_dts_test.squeeze().T - dts_test_pred.T)/X_dts_test.squeeze().T, cmap='seismic', aspect='auto')\n",
    "# plt.colorbar(); plt.title('Normalized Relative Error - Test')\n",
    "# plt.show()\n",
    "\n",
    "# dts_pred = np.vstack((dts_train_pred, dts_test_pred))\n",
    "# plt.figure(figsize=(15,4))\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(X_dts.squeeze().T, cmap='seismic', aspect='auto', vmin=0, vmax=1)\n",
    "# plt.colorbar(); plt.title('DTS Original')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(dts_pred.T, cmap='seismic', aspect='auto', vmin=0, vmax=1)\n",
    "# plt.colorbar(); plt.title('DTS Reconstruction')\n",
    "# plt.subplot(133)\n",
    "# plt.imshow((X_dts.squeeze().T - dts_pred.T)/X_dts.squeeze().T, cmap='seismic', aspect='auto')\n",
    "# plt.colorbar(); plt.title('Normalized Relative Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64\n",
    "exp_flow = np.array([[3000, 100000,   0,    0],\n",
    "                     [250,  8333.33,  250,  0],\n",
    "                     [250,  8333.33,  100,  0],\n",
    "                     [0,    0,        0,    0],\n",
    "                     [250,  8333.33,  250,  0]])\n",
    "\n",
    "# 128\n",
    "exp_flow = np.array([[3000, 60000,  0,   0],\n",
    "                     [500,  20000,  0,   0],\n",
    "                     [500,  20000,  0,   0],\n",
    "                     [0,    0,      0,   0],\n",
    "                     [500,  20000,  0,   5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = pd.read_pickle('E:/Lytt Fiber Optics/data_exp128.pkl')\n",
    "dts = pd.read_pickle('E:/Lytt Fiber Optics/dts_exp128.pkl')\n",
    "exp_flow = np.array([[3000, 60000,  0,   0],\n",
    "                     [500,  20000,  0,   0],\n",
    "                     [500,  20000,  0,   0],\n",
    "                     [0,    0,      0,   0],\n",
    "                     [500,  20000,  0,   5]])\n",
    "\n",
    "das_dec = signal.decimate(signal.decimate(das,10),10)\n",
    "\n",
    "flowrates = np.zeros((200,4))\n",
    "flowrates[115] = exp_flow[0]\n",
    "flowrates[126] = exp_flow[1]\n",
    "flowrates[138] = exp_flow[2]\n",
    "flowrates[142] = exp_flow[3]\n",
    "flowrates[152] = exp_flow[4]\n",
    "\n",
    "X_das = np.expand_dims(Normalizer('max').fit_transform(das_dec.T), -1)\n",
    "X_dts = np.expand_dims(MinMaxScaler().fit_transform(dts.T), -1)\n",
    "y_flow = MinMaxScaler().fit_transform(flowrates)\n",
    "\n",
    "das_z = das_m2z.predict(X_das).squeeze().astype('float64')\n",
    "dts_z = dts_m2z.predict(X_dts).squeeze().astype('float64')\n",
    "\n",
    "z_dual = np.concatenate([das_z, dts_z])\n",
    "y_flow_exp = np.repeat(y_flow[np.newaxis, :, :], z_dual.shape[0], axis=0)\n",
    "\n",
    "y_flow_pred = flow_net.predict(z_dual)\n",
    "mse  = mean_squared_error(y_flow_exp, y_flow_pred)\n",
    "ssim = structural_similarity(y_flow_exp, y_flow_pred, channel_axis=-1)\n",
    "print('MSE={:.3e} | SSIM={:.5f}'.format(mse,ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,10), facecolor='white')\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.imshow(y_flow_exp[0], aspect='auto', cmap='turbo')\n",
    "plt.title('Normalized Injection Rate Map'); plt.colorbar()\n",
    "plt.xticks([0,1,2,3], labels=['oil','water','gas','sand']); plt.ylabel('distance')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.imshow(y_flow_pred.mean(0), aspect='auto', cmap='turbo', vmin=0, vmax=1)\n",
    "plt.title('Predicted Injection Rate Map'); plt.colorbar()\n",
    "plt.xticks([0,1,2,3], labels=['oil','water','gas','sand']); plt.ylabel('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/z_train_dual.npy', z_train_dual)\n",
    "np.save('models/z_test_dual.npy', z_test_dual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(svd_solver='full', whiten=True)\n",
    "pca.fit(z_train_dual.reshape(z_train_dual.shape[0], z_train_dual.shape[1]*z_train_dual.shape[-1]))\n",
    "z_pca = pca.transform(z_train_dual.reshape(z_train_dual.shape[0], z_train_dual.shape[1]*z_train_dual.shape[-1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(pca.components_, histtype='stepfilled', bins=20, density=True, edgecolor='k')\n",
    "plt.vlines(pca.components_.mean() + 2*pca.components_.std(), 0, 15, 'k', linestyle='--', linewidth=2)\n",
    "plt.vlines(pca.components_.mean() - 2*pca.components_.std(), 0, 15, 'k', linestyle='--', linewidth=2)\n",
    "plt.xlim([-.20,.20]); plt.legend(range(10))\n",
    "plt.show()\n",
    "\n",
    "pca.components_[pca.components_ >= pca.components_.mean() + 2*pca.components_.std()] = 0\n",
    "pca.components_[pca.components_ <= pca.components_.mean() - 2*pca.components_.std()] = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(pca.components_, histtype='stepfilled', bins=20, density=True, edgecolor='k')\n",
    "plt.xlim([-.2,.2]); plt.legend(range(10))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(z_train_dual.reshape(z_train_dual.shape[0], z_train_dual.shape[1]*z_train_dual.shape[-1]).T, aspect='auto', cmap='magma', vmin=0, vmax=1)\n",
    "plt.imshow(pca.inverse_transform(z_pca).T, aspect='auto', cmap='magma', vmin=0, vmax=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
